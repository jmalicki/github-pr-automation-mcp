# Design Phase Summary

## Overview

Comprehensive design documentation has been completed for the **Resolve PR MCP Server** - an AI-powered GitHub Pull Request management system.

## What Was Created

### Project Structure

```
resolve-pr-mcp/
â”œâ”€â”€ package.json                    # Node.js project configuration
â”œâ”€â”€ tsconfig.json                   # TypeScript configuration
â”œâ”€â”€ README.md                       # Main documentation
â”œâ”€â”€ .gitignore                      # Git ignore rules
â””â”€â”€ docs/                          # Comprehensive design docs
    â”œâ”€â”€ INDEX.md                   # Documentation overview
    â”œâ”€â”€ DESIGN_DECISIONS.md        # Key design choices & rationale
    â”œâ”€â”€ ARCHITECTURE.md            # System architecture
    â”œâ”€â”€ API_DESIGN.md              # Complete API specs (8 tools)
    â”œâ”€â”€ DATA_MODELS.md             # TypeScript type definitions
    â”œâ”€â”€ IMPLEMENTATION_PLAN.md     # Development roadmap with [ ] checkboxes
    â”œâ”€â”€ GITHUB_INTEGRATION.md      # GitHub API patterns
    â”œâ”€â”€ TESTING_STRATEGY.md        # Test approach & examples
    â”œâ”€â”€ USAGE_EXAMPLES.md          # Real-world workflows
    â”œâ”€â”€ PREFERENCE_HINTS.md        # User preference system (ðŸ’¾)
    â””â”€â”€ AI_DECISION_GUIDE.md       # AI agent decision trees
```

**Total Documentation**: 11 comprehensive documents

## Core Tools Designed

### 1. get_failing_tests

**Purpose**: Analyze PR CI failures and provide targeted fix instructions

**Key Features**:

- âœ… Wait for CI completion or return immediately
- âœ… Bail on first failure for fast feedback
- âœ… Parse multiple test framework outputs (Jest, pytest, Go, RSpec)
- âœ… Generate reproduction commands
- âœ… Paginated results with prioritization

**Unique Value**: Extracts exact failing tests from CI logs instead of making AI parse raw logs

### 2. find_unresolved_comments

**Purpose**: Find unresolved PR comments and return raw data for LLM analysis

**Key Features**:

- âœ… Fetches all comment types (review, issue, inline)
- âœ… Builds conversation threads
- âœ… Includes bot comments by default (LLM filters)
- âœ… Returns raw data with reactions, author info
- âœ… Sort by chronological, file, or author

**Design Update**: Tool provides **raw data only** - LLM handles categorization and response generation

### 3. manage_stacked_prs

**Purpose**: Automate rebase and testing of stacked (dependent) PRs

**Key Features**:

- âœ… Verifies PR dependency chains
- âœ… Detects when rebase is needed
- âœ… Generates step-by-step rebase commands
- âœ… Integrates with get_failing_tests for automated fix loops
- âœ… Risk assessment and conflict prediction

**Unique Value**: Automates tedious stacked PR maintenance with AI-driven fix loops

## Supplementary Tools Designed

4. **detect_merge_conflicts** - Proactive conflict detection
5. **check_merge_readiness** - Comprehensive merge validation
6. **analyze_pr_impact** - Change impact analysis
7. **get_review_suggestions** - AI-optimized review context
8. **rebase_after_squash_merge** - Clean rebase using `--onto` after upstream squash-merge

**Note on #8**: This tool solves a specific but common problem: when an upstream PR in your stack gets squash-merged, regular `git rebase` tries to replay those commits (causing conflicts). This tool uses `git rebase --onto` to skip the upstream commits entirely and only rebase YOUR commits, resulting in a clean rebase with minimal conflicts.

These supplementary tools enhance the core workflow but are considered lower priority than the core 3 tools.

## Key Design Decisions

### 1. PR Identifier Format âœ…

**Decision**: Use single string `"owner/repo#123"`

- More concise for AI agents
- Supports multiple formats (URLs, etc.)
- Human-friendly

### 2. Tool Responsibilities âœ…

**Decision**: Tools provide raw data, LLMs analyze

- Tools: Fetch and structure GitHub data
- LLMs: Categorize, prioritize, generate responses
- Better separation of concerns
- More accurate results (LLM understands context)

**Example**: Tool returns comment text and metadata â†’ LLM determines if it's "blocking", "nit", or "question"

### 3. Bot Filtering âœ…

**Decision**: Include bots by default

- Neutral default - no assumptions
- LLM can filter based on content
- User can explicitly exclude via `exclude_authors`

### 4. Pagination âœ…

**Decision**: Mandatory with sensible defaults

- Token efficiency (don't return 500 comments at once)
- Default sizes: 10 for tests, 20 for comments, 5 for commands
- Progressive disclosure

### 5. Wait vs. Immediate âœ…

**Decision**: Support both, default to immediate

- Fast responses by default (<2s)
- Wait mode for convenience (CI polling)
- Bail-on-first for rapid feedback

## Architecture Highlights

### Dual Mode: MCP (stdio) + CLI

**Primary: MCP Server (stdio)**

- âœ… No HTTP server, no ports, no daemon
- âœ… MCP client spawns as subprocess
- âœ… Communicates via stdin/stdout (JSON-RPC)
- âœ… Process lifecycle managed by client

**Bonus: CLI Mode**

- âœ… Direct command-line invocation
- âœ… Perfect for testing and scripting
- âœ… CI/CD integration
- âœ… JSON or human-readable output

```bash
# MCP mode (primary)
node dist/index.js  # stdio transport for AI agents

# CLI mode (testing/automation)
resolve-pr-mcp get-failing-tests --pr "owner/repo#123" --json
```

### Layer Structure

```
AI Agent (Claude Desktop/etc)
      â†“ Spawns subprocess
MCP Server Process (node dist/index.js)
      â†“ stdio/JSON-RPC (not HTTP!)
Tool Handlers Layer (Input validation, pagination, formatting)
      â†“
GitHub Integration Layer (CI status, comments, PR analysis)
      â†“
Octokit Client (Rate limiting, auth, requests)
      â†“
GitHub API (HTTPS)
```

### Design Principles

1. **Token Efficiency**: Pre-filter and structure data to minimize AI token usage
2. **Actionability**: Return commands and instructions, not just observations
3. **Incremental Processing**: Mandatory pagination with sensible defaults
4. **Fail-Fast**: Bail on first failure for rapid iteration
5. **Stateless**: No session state, each call independent

## Implementation Roadmap

### Phase 1: Foundation (Week 1)

- Project setup and MCP server skeleton
- GitHub API client wrapper
- Core utilities (parser, pagination, formatting)

### Phase 2: Core Tools (Weeks 2-3)

- Implement get_failing_tests (with log parsers)
- Implement find_unresolved_comments (with thread analysis)
- Implement manage_stacked_prs (with command generation)

### Phase 3: Enhanced Tools (Week 4)

- Conflict detection
- Merge readiness checks
- Impact analysis
- Review suggestions

### Phase 4: Optimization (Week 5)

- Caching layer
- Rate limiting improvements
- Error recovery
- Performance tuning

### Phase 5: Polish (Week 6)

- Complete documentation
- Usage examples
- Deployment tooling
- Performance benchmarks

**Estimated Total**: 6 weeks to production-ready v1.0

## Testing Strategy

### Coverage Targets

- Unit tests: >90% coverage
- Integration tests: >80% coverage
- Critical paths: 100% coverage

### Test Organization

```
tests/
â”œâ”€â”€ fixtures/          # Mock GitHub API responses
â”‚   â”œâ”€â”€ pull-requests/
â”‚   â”œâ”€â”€ check-runs/
â”‚   â”œâ”€â”€ logs/
â”‚   â””â”€â”€ comments/
â”œâ”€â”€ mocks/            # Mock implementations
â”‚   â””â”€â”€ github-client.ts
â”œâ”€â”€ unit/             # Unit tests
â”œâ”€â”€ integration/      # Integration tests
â””â”€â”€ e2e/             # End-to-end tests (optional)
```

### Key Test Scenarios

- 15+ scenarios per core tool
- All error cases covered
- Pagination edge cases
- Rate limiting simulation

## Documentation Quality

### Comprehensive Coverage

- **11 design documents** covering all aspects
- **Real-world examples** for every tool
- **Complete API specifications** with TypeScript types
- **Implementation plan** with [ ] checkboxes
- **Testing strategy** with example tests
- **User preference system** with ðŸ’¾ hints
- **AI decision guides** for complex scenarios

### Key Documentation Files

1. **[INDEX.md](docs/INDEX.md)** - Navigation hub
2. **[DESIGN_DECISIONS.md](docs/DESIGN_DECISIONS.md)** - 9 key decisions with rationale
3. **[ARCHITECTURE.md](docs/ARCHITECTURE.md)** - System architecture (stdio + CLI)
4. **[API_DESIGN.md](docs/API_DESIGN.md)** - 8 tools fully specified
5. **[DATA_MODELS.md](docs/DATA_MODELS.md)** - Complete TypeScript type definitions
6. **[IMPLEMENTATION_PLAN.md](docs/IMPLEMENTATION_PLAN.md)** - 6-week roadmap with checkboxes
7. **[GITHUB_INTEGRATION.md](docs/GITHUB_INTEGRATION.md)** - GitHub API patterns
8. **[TESTING_STRATEGY.md](docs/TESTING_STRATEGY.md)** - Testing approach
9. **[USAGE_EXAMPLES.md](docs/USAGE_EXAMPLES.md)** - 7+ workflow examples
10. **[PREFERENCE_HINTS.md](docs/PREFERENCE_HINTS.md)** - User preference system
11. **[AI_DECISION_GUIDE.md](docs/AI_DECISION_GUIDE.md)** - AI agent decision trees

## What's Next

### Ready for Implementation âœ…

All design phase deliverables are complete:

- âœ… Architecture defined
- âœ… APIs specified  
- âœ… Data models documented
- âœ… Implementation plan created
- âœ… Testing strategy defined
- âœ… Examples provided

### To Start Development

1. **Initialize dependencies**: `npm install`
2. **Follow Phase 1** in [IMPLEMENTATION_PLAN.md](docs/IMPLEMENTATION_PLAN.md)
3. **Reference designs** as you implement
4. **Write tests** per [TESTING_STRATEGY.md](docs/TESTING_STRATEGY.md)

### Key Implementation Files to Create

```
src/
â”œâ”€â”€ index.ts                       # MCP server entry point
â”œâ”€â”€ server.ts                      # Server configuration
â”œâ”€â”€ types/                         # Type definitions
â”œâ”€â”€ github/                        # GitHub API layer
â”‚   â”œâ”€â”€ client.ts
â”‚   â”œâ”€â”€ ci-status-fetcher.ts
â”‚   â”œâ”€â”€ comment-manager.ts
â”‚   â””â”€â”€ pr-analyzer.ts
â”œâ”€â”€ tools/                         # Tool handlers
â”‚   â”œâ”€â”€ get-failing-tests/
â”‚   â”œâ”€â”€ find-unresolved-comments/
â”‚   â””â”€â”€ manage-stacked-prs/
â””â”€â”€ utils/                         # Utilities
    â”œâ”€â”€ parser.ts
    â”œâ”€â”€ pagination.ts
    â””â”€â”€ formatting.ts
```

## Success Metrics

### Functional

- All 7 core tools implemented
- >85% test coverage
- All APIs work as specified

### Performance

- Average response <2s (immediate mode)
- <100 GitHub API calls per tool invocation
- <200MB memory usage

### Quality

- Zero critical bugs
- All error cases handled
- Complete documentation

## Questions Addressed

### Q: PR identifier - single string or separate fields?

**A**: Single string `"owner/repo#123"` - more AI-friendly, supports multiple formats

### Q: Should we filter bots by default?

**A**: No - include by default, let LLM filter based on content

### Q: What should find_unresolved_comments return?

**A**: Raw data only - LLM handles categorization, severity, response generation

## Conclusion

The design phase is **complete and comprehensive**. The project is ready for implementation with:

- âœ… Clear architecture
- âœ… Detailed specifications  
- âœ… Complete type definitions
- âœ… Step-by-step implementation plan
- âœ… Testing strategy
- âœ… Real-world examples
- âœ… Future roadmap

**Total Documentation**: 11 comprehensive documents providing complete guidance from design through deployment, including implementation checklists.

---

**Ready to implement!** ðŸš€

Start with [docs/IMPLEMENTATION_PLAN.md](docs/IMPLEMENTATION_PLAN.md) Phase 1.
